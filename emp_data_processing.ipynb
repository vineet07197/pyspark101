{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf023e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import when,col,regexp_replace,regexp_extract,cast,row_number\n",
    "from pyspark.sql.functions import concat_ws,count,isnan,round,avg,coalesce,lit,udf,StringType\n",
    "spark=SparkSession.builder.master(\"local\").appName(\"emp_clean\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4db19e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "inp_file1='all_emp.csv'\n",
    "inp_file2='left_emp.csv'\n",
    "inp_file_path=os.getcwd()+'/../datafiles/input/'\n",
    "op_file_path=os.getcwd()+'/../datafiles/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eace1fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: integer (nullable = true)\n",
      " |-- f_name: string (nullable = true)\n",
      " |-- l_name: string (nullable = true)\n",
      " |-- emp_dept: string (nullable = true)\n",
      " |-- doj: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- mngr_id: integer (nullable = true)\n",
      " |-- total_exp: string (nullable = true)\n",
      " |-- location: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw_allemp=spark.read.format('csv').option('header',True).option('inferSchema',True).load(inp_file_path+inp_file1)\n",
    "df_raw_allemp.printSchema()\n",
    "df_raw_left=spark.read.format('csv').option('header',True).option('inferSchema',True).load(inp_file_path+inp_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3658ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformations:\n",
    "\n",
    "#1 Add a country field 'India'/'USA' and account 'Reliance'\n",
    "#2 Clean total_exp field and convert it to Integer type and also remove whitespaces from department table\n",
    "#3 Convert first letters of f_name and l_name in capital\n",
    "#4 Combine f_name and l_name\n",
    "#5 drop f_name and l_name\n",
    "#6 Check and clean all the null/NAN values\n",
    "#7 Impute salary where it is null, as average of the salaries of respective department\n",
    "\n",
    "#8  Create bonus column for the currently working employees >1Lac: 17%;70k<15%,50k<12%,else 10%\n",
    "#9 Based on the final salary, rank the employees by their experience, final salary dept-wise\n",
    "#10 Save the final data in parquet format and exclude the intern role partition by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71cf29e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+---+----+------+-------+---------+--------+-------+\n",
      "|emp_id|name|emp_dept|doj|city|salary|mngr_id|total_exp|location|account|\n",
      "+------+----+--------+---+----+------+-------+---------+--------+-------+\n",
      "|     1|   0|       2|  1|   3|     5|      0|        2|       0|      0|\n",
      "+------+----+--------+---+----+------+-------+---------+--------+-------+\n",
      "\n",
      "+------+----+--------+---+----+------+-------+---------+--------+-------+\n",
      "|emp_id|name|emp_dept|doj|city|salary|mngr_id|total_exp|location|account|\n",
      "+------+----+--------+---+----+------+-------+---------+--------+-------+\n",
      "|     0|   0|       0|  0|   0|     0|      0|        0|       0|      0|\n",
      "+------+----+--------+---+----+------+-------+---------+--------+-------+\n",
      "\n",
      "+------+-------------------+--------+-----------+----------+--------+-------+---------+--------+-----------------+------------------+\n",
      "|emp_id|               name|emp_dept|        doj|      city|  salary|mngr_id|total_exp|location|     manager_name|             bonus|\n",
      "+------+-------------------+--------+-----------+----------+--------+-------+---------+--------+-----------------+------------------+\n",
      "|   101|       Satish Kumar|designer| 12/12/2012|     Vizag| 98000.0|    100|       10|   India|    Rajeev Gautam|           14700.0|\n",
      "|   102|  Shivani Srivastav|designer| 15/08/2016|     Noida| 72000.0|    100|        6|   India|    Rajeev Gautam|           10800.0|\n",
      "|   110|       Radha Patole|designer| 11/08/2015|      Pune| 95000.0|    100|        7|   India|    Rajeev Gautam|           14250.0|\n",
      "|   114|         Raman Jain|designer| 20/06/2014|   Kolkata| 88333.0|    109|        8|     USA|       Jetha Seth|13249.949999999999|\n",
      "|   104|Akshara Parthsarthy|     dev| 25/03/2017|    Cochin| 45000.0|    102|        5|   India|Shivani Srivastav|            4500.0|\n",
      "|   108|      Prashant Veer|     dev| 15/04/2020|   Ayodhya| 35000.0|    101|        2|   India|     Satish Kumar|            3500.0|\n",
      "|   111|    Niharika Sherpa|     dev| 20/02/2018|   Gangtok| 50000.0|    110|        4|   India|     Radha Patole|            6000.0|\n",
      "|   115|       Pulkit Anand|     dev| 22/04/2017|     Noida| 45000.0|    114|        5|     USA|       Raman Jain|            4500.0|\n",
      "|   116| Jyothirmayi Koduru|     dev| 31/03/2019|Vijayawada| 45000.0|    114|        3|     USA|       Raman Jain|            4500.0|\n",
      "|   100|      Rajeev Gautam| manager|  10/6/2011|      Kota|110000.0|    109|       13|     USA|       Jetha Seth|           18700.0|\n",
      "|   109|         Jetha Seth| manager| 15/07/2008|    Meerut|200000.0|   1010|       14|     USA|             null|           34000.0|\n",
      "|   105|          Vivek Das|  tester| 31/01/2018|    Indore| 47000.0|    102|        4|   India|Shivani Srivastav|            4700.0|\n",
      "|   106|       Vedika Shree|  tester|  4/04/2017|    Prayag| 35000.0|    101|        5|   India|     Satish Kumar|            3500.0|\n",
      "|   113|    Vikrant Prakash|  tester| 31/03/2018|Chandigarh| 45000.0|    110|        4|   India|     Radha Patole|            4500.0|\n",
      "|   117|  Krishna Chaitanya|  tester| 31/03/2018|     Salem| 42333.0|    114|        4|     USA|       Raman Jain|            4233.3|\n",
      "+------+-------------------+--------+-----------+----------+--------+-------+---------+--------+-----------------+------------------+\n",
      "\n",
      "+------+-------------------+--------+-----------+----------+---------+-------+---------+--------+-----------------+---------+\n",
      "|emp_id|               name|emp_dept|        doj|      city|   salary|mngr_id|total_exp|location|     manager_name|dept_rank|\n",
      "+------+-------------------+--------+-----------+----------+---------+-------+---------+--------+-----------------+---------+\n",
      "|   101|       Satish Kumar|designer| 12/12/2012|     Vizag| 112700.0|    100|       10|   India|    Rajeev Gautam|        1|\n",
      "|   114|         Raman Jain|designer| 20/06/2014|   Kolkata|101582.95|    109|        8|     USA|       Jetha Seth|        2|\n",
      "|   110|       Radha Patole|designer| 11/08/2015|      Pune| 109250.0|    100|        7|   India|    Rajeev Gautam|        3|\n",
      "|   102|  Shivani Srivastav|designer| 15/08/2016|     Noida|  82800.0|    100|        6|   India|    Rajeev Gautam|        4|\n",
      "|   104|Akshara Parthsarthy|     dev| 25/03/2017|    Cochin|  49500.0|    102|        5|   India|Shivani Srivastav|        1|\n",
      "|   115|       Pulkit Anand|     dev| 22/04/2017|     Noida|  49500.0|    114|        5|     USA|       Raman Jain|        2|\n",
      "|   111|    Niharika Sherpa|     dev| 20/02/2018|   Gangtok|  56000.0|    110|        4|   India|     Radha Patole|        3|\n",
      "|   116| Jyothirmayi Koduru|     dev| 31/03/2019|Vijayawada|  49500.0|    114|        3|     USA|       Raman Jain|        4|\n",
      "|   108|      Prashant Veer|     dev| 15/04/2020|   Ayodhya|  38500.0|    101|        2|   India|     Satish Kumar|        5|\n",
      "|   109|         Jetha Seth| manager| 15/07/2008|    Meerut| 234000.0|   1010|       14|     USA|             null|        1|\n",
      "|   100|      Rajeev Gautam| manager|  10/6/2011|      Kota| 128700.0|    109|       13|     USA|       Jetha Seth|        2|\n",
      "|   106|       Vedika Shree|  tester|  4/04/2017|    Prayag|  38500.0|    101|        5|   India|     Satish Kumar|        1|\n",
      "|   105|          Vivek Das|  tester| 31/01/2018|    Indore|  51700.0|    102|        4|   India|Shivani Srivastav|        2|\n",
      "|   113|    Vikrant Prakash|  tester| 31/03/2018|Chandigarh|  49500.0|    110|        4|   India|     Radha Patole|        3|\n",
      "|   117|  Krishna Chaitanya|  tester| 31/03/2018|     Salem|  46566.3|    114|        4|     USA|       Raman Jain|        4|\n",
      "+------+-------------------+--------+-----------+----------+---------+-------+---------+--------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 Add a country field 'India'/'USA' and account 'Reliance'\n",
    "df_res1=df_raw_allemp.withColumn(\"location\",when(col('location')==1,'India').when(col('location')==0,'USA'))\n",
    "df_res1=df_res1.withColumn('account',lit(\"Reliance\"))\n",
    "#df_res2.show()\n",
    "\n",
    "#2 Clean total_exp field and convert it to Integer type and also remove whitespaces from department table\n",
    "df_res2=df_res1.withColumn('total_exp',regexp_extract('total_exp','\\d+',0))\n",
    "df_res2=df_res2.withColumn('total_exp',col('total_exp').cast('Integer'))\n",
    "df_res2=df_res2.withColumn('emp_dept',regexp_replace(col('emp_dept'),'\\s',''))\n",
    "#df_res2.show()\n",
    "#df_res2.printSchema()\n",
    "\n",
    "#3 Convert first letters of f_name and l_name in capital\n",
    "def convert_to_upper(string):\n",
    "    string=string.replace(\" \",\"\")\n",
    "    string=string[0].upper()+string[1:]\n",
    "    return string\n",
    "\n",
    "convert_df_upper=udf(lambda string:convert_to_upper(string),StringType())\n",
    "df_res3=df_res2.withColumn('f_name',convert_df_upper(col('f_name')))\n",
    "df_res3=df_res3.withColumn('l_name',convert_df_upper(col('l_name')))\n",
    "#df_res3.show()\n",
    "\n",
    "#4 Combine f_name and l_name\n",
    "df_res4=df_res3.withColumn('f_name',concat_ws(' ',col('f_name'),col('l_name')))\n",
    "\n",
    "#5 drop f_name and l_name\n",
    "df_res5=df_res4.withColumnRenamed('f_name','name').drop('l_name')\n",
    "\n",
    "#df_res5.show()\n",
    "\n",
    "#df_res5=df_res5.withColumn('manager_name',df_res5.alias('emp1') \\\n",
    "#        .join(df_res5.alias('emp2'),col('emp1.mngr_id')==col('emp2.emp_id'),'left') \\\n",
    "#        .select(col('emp2.name').alias('manager_name')))\n",
    "\n",
    "#6 Check and clean all the null/NAN values\n",
    "df_res5.select([count(when(isnan(s) | col(s).isNull(),s)).alias(s) for s in df_res5.columns]).show()\n",
    "#|emp_id|name|emp_dept|doj|city|salary|mngr_id|total_exp|location|account|\n",
    "#|     1|   0|       2|  1|   3|     5|      0|        2|       0|      0|\n",
    "\n",
    "df_res6=df_res5.dropna(subset=['emp_id','emp_dept','total_exp'])#.dropna(subset='')\n",
    "\n",
    "#df_res6.select([count(when(isnan(s) | col(s).isNull(),s)).alias(s) for s in df_res5.columns]).show()\n",
    "#|emp_id|name|emp_dept|doj|city|salary|mngr_id|total_exp|location|account|\n",
    "#|     0|   0|       0|  0|   0|     4|      0|        0|       0|      0|\n",
    "\n",
    "#filling the salary null fields with the average salary of respective departmens\n",
    "spec1=Window.partitionBy('emp_dept')\n",
    "\n",
    "#7 Impute salary where it is null, as average of the salaries of respective department\n",
    "df_res7=df_res6.withColumn('salary',coalesce('salary',round(avg('salary').over(spec1))))\n",
    "#df_res7.show()\n",
    "#df_res7.select([count(when(isnan(s) | col(s).isNull(),s)).alias(s) for s in df_res5.columns]).show()\n",
    "#|emp_id|name|emp_dept|doj|city|salary|mngr_id|total_exp|location|account|\n",
    "#|     0|   0|       0|  0|   0|     0|      0|        0|       0|      0|\n",
    "\n",
    "#8 Create manager column and\n",
    "#Create bonus column for the currently working employees only >1Lac: 17%;70k<15%,50k<12%,else 10%\n",
    "\n",
    "#fetching the current employees only\n",
    "df_res8=df_res7.join(df_raw_left,df_res7.emp_id==df_raw_left.emp_id,'leftanti')\n",
    "\n",
    "#adding managers column\n",
    "df_res8=df_res8.alias('emp1') \\\n",
    "        .join(df_res5.alias('emp2'),col('emp1.mngr_id')==col('emp2.emp_id'),'left') \\\n",
    "        .select(col('emp1.emp_id'),col('emp1.name'),col('emp1.emp_dept'),col('emp1.doj'), \\\n",
    "                col('emp1.city'),col('emp1.salary'),col('emp1.mngr_id'),col('emp1.total_exp'), \\\n",
    "                col('emp1.location'),col('emp2.name').alias('manager_name'))\n",
    "\n",
    "#adding bonus column\n",
    "condition=when(col('salary')>=100000,col('salary')*.17) \\\n",
    "    .when(col('salary')>=70000,col('salary')*.15) \\\n",
    "    .when(col('salary')>=50000,col('salary')*.12) \\\n",
    "    .otherwise(col('salary')*.10)\n",
    "\n",
    "df_res8=df_res8.withColumn('bonus',condition)\n",
    "df_res8.show()\n",
    "df_res8=df_res8.withColumn('salary',col('salary')+col('bonus')).drop('bonus')\n",
    "#df_res8.show()\n",
    "\n",
    "#9 Based on the final salary, rank the employees by their experience, final salary dept-wise\n",
    "\n",
    "spec2=Window.partitionBy(col('emp_dept')).orderBy(col('total_exp').desc(),(col('salary')).desc())\n",
    "df_res9=df_res8.withColumn('dept_rank',row_number().over(spec2))\n",
    "#df_res9.select(col('name'),col('emp_dept'),col('salary'),col('bonus'),col('total_exp'),col('dept_rank')).show()\n",
    "#df_res9.show()\n",
    "\n",
    "#10 Save the final data in parquet format and exclude the intern role partition by country\n",
    "\n",
    "df_res9.write.mode('overwrite').partitionBy('location').parquet(op_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab506f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f3a86f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
