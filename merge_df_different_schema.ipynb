{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "709bd973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/15 14:43:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/12/15 14:43:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark=SparkSession.builder.master('local').appName('learn_pyspark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2dd2cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----+----------+\n",
      "|emp_id|emp_name|city|manager_id|\n",
      "+------+--------+----+----------+\n",
      "|   101|     Abc| DEL|      1101|\n",
      "|   102|     Def| MUB|      1102|\n",
      "|   103|     Ghi| BHV|      1102|\n",
      "|   104|     Jkl| CHE|      1101|\n",
      "+------+--------+----+----------+\n",
      "\n",
      "+------+--------+---------+----------+\n",
      "|emp_id|emp_name|dept_name|experience|\n",
      "+------+--------+---------+----------+\n",
      "|   105|     Mno| Designer|        12|\n",
      "|   106|     Pqr| Designer|        11|\n",
      "|   107|     Stu|  Testing|         7|\n",
      "|   108|     Vwx|      Dev|         5|\n",
      "+------+--------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining schemas for both the dataframes\n",
    "schema1=['emp_id','emp_name','city','manager_id',]\n",
    "schema2=['emp_id','emp_name','dept_name','experience']\n",
    "\n",
    "#creating some ata for both the dataframes\n",
    "data1=[[101,'Abc','DEL',1101],[102,'Def','MUB',1102],[103,'Ghi','BHV',1102],[104,'Jkl','CHE',1101]]\n",
    "data2=[[105,'Mno','Designer',12],[106,'Pqr','Designer',11],[107,'Stu','Testing',7],[108,'Vwx','Dev',5]]\n",
    "\n",
    "\n",
    "df_emp1=spark.createDataFrame(data1,schema1)\n",
    "df_emp2=spark.createDataFrame(data2,schema2)\n",
    "\n",
    "df_emp1.show()\n",
    "df_emp2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ffaaa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----+----------+---------+----------+\n",
      "|emp_id|emp_name|city|manager_id|dept_name|experience|\n",
      "+------+--------+----+----------+---------+----------+\n",
      "|   101|     Abc| DEL|      1101|     null|      null|\n",
      "|   102|     Def| MUB|      1102|     null|      null|\n",
      "|   103|     Ghi| BHV|      1102|     null|      null|\n",
      "|   104|     Jkl| CHE|      1101|     null|      null|\n",
      "|   105|     Mno|null|      null| Designer|        12|\n",
      "|   106|     Pqr|null|      null| Designer|        11|\n",
      "|   107|     Stu|null|      null|  Testing|         7|\n",
      "|   108|     Vwx|null|      null|      Dev|         5|\n",
      "+------+--------+----+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def match_schema(df1,df2):\n",
    "    for column in df1.columns:\n",
    "        if column not in df2.columns:\n",
    "            df2=df2.withColumn(column,lit(None))\n",
    "            \n",
    "    for column in df2.columns:\n",
    "        if column not in df1.columns:\n",
    "            df1=df1.withColumn(column,lit(None))\n",
    "            \n",
    "    return df1,df2\n",
    "\n",
    "#calling the macth_schema function here\n",
    "df_emp1,df_emp2=match_schema(df_emp1,df_emp2)\n",
    "#df_emp1.show()\n",
    "#df_emp2.show()\n",
    "\n",
    "#unionByName Function to merge both the dataframes\n",
    "df_emp=df_emp1.unionByName(df_emp2)\n",
    "\n",
    "df_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0df956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d3ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
